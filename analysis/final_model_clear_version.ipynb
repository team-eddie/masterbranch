{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# images data : train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T02:53:34.717033Z",
     "start_time": "2019-02-26T02:53:34.712344Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import keras\n",
    "from keras.layers import *\n",
    "# Input ,Dense, Dropout, Activation, LSTM, Add\n",
    "# from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape, concatenate, Add, merge, Lambda\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.utils import *\n",
    "#  np_utils\n",
    "# from keras.utils import np_utils\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras import metrics\n",
    "from keras import optimizers \n",
    "from keras import losses\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import scale, robust_scale, minmax_scale, maxabs_scale\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "import cv2\n",
    "\n",
    "import PIL\n",
    "import PIL.Image as pi\n",
    "from PIL import Image\n",
    "\n",
    "from numpy.random import seed\n",
    "# set_random_seed(3)\n",
    "# seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T02:09:02.370932Z",
     "start_time": "2019-02-26T02:09:00.696296Z"
    }
   },
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd '' # good match 파일 경로로 이동\n",
    "file_list_new = os.listdir()\n",
    "file_list_new.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T13:53:34.666876Z",
     "start_time": "2019-02-25T13:53:34.619882Z"
    }
   },
   "outputs": [],
   "source": [
    "file_list = []\n",
    "cor_v_num= 1\n",
    "for idx,i in enumerate(file_list_new):\n",
    "    if 'jpg' in i:\n",
    "        if idx < 242*cor_v_num: # 개\n",
    "            file_list.append(i)\n",
    "# print(file_list2,len(file_list2))\n",
    "# [v_file_set.append(v_file_list2[i:i+242]) for i in range(0, len(v_file_list2), 242)]\n",
    "# v_images_set = np.asarray(v_file_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T13:56:13.822536Z",
     "start_time": "2019-02-25T13:53:35.822432Z"
    }
   },
   "outputs": [],
   "source": [
    "img_info = []\n",
    "images = []\n",
    "new=[]\n",
    "for idx,i in enumerate (file_list):\n",
    "    if 'jpg' in i:\n",
    "        if idx < 242 * cor_v_num: #200개\n",
    "            img = cv2.imread('{}'.format(i), cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, dsize=(150, 150), interpolation=cv2.INTER_AREA) # 퍼센트로 줄이자\n",
    "            img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F) #scaling 방식 (255로 나누자)\n",
    "            img_info.append(img)\n",
    "        else:\n",
    "            break\n",
    "new =np.asarray(img_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T13:56:14.081615Z",
     "start_time": "2019-02-25T13:56:13.824261Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd '' # bad match 파일 경로로 이동\n",
    "file_list_origin = os.listdir()\n",
    "file_list_origin.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T13:56:14.132531Z",
     "start_time": "2019-02-25T13:56:14.083351Z"
    }
   },
   "outputs": [],
   "source": [
    "file_list=[]\n",
    "wron_v_num=1\n",
    "for idx,i in enumerate(file_list_origin):\n",
    "    if 'jpg' in i:\n",
    "        if idx < 242 * wron_v_num: # 200개\n",
    "            file_list.append(i)\n",
    "\n",
    "# print(file_list2,len(file_list2))\n",
    "# [v_file_set.append(v_file_list2[i:i+242]) for i in range(0, len(v_file_list2), 242)]\n",
    "# v_images_set = np.asarray(v_file_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T14:03:14.792676Z",
     "start_time": "2019-02-25T13:56:14.134115Z"
    }
   },
   "outputs": [],
   "source": [
    "img_info= []\n",
    "\n",
    "for idx,i in enumerate (file_list):\n",
    "    if 'jpg' in i:\n",
    "        if idx < 242 * wron_v_num: # 500\n",
    "            img = cv2.imread('{}'.format(i), cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, dsize=(150, 150), interpolation=cv2.INTER_AREA) # 퍼센트로 줄이자\n",
    "            img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F) #scaling 방식 (255로 나누자)\n",
    "            img_info.append(img)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "origin=np.asarray(img_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T14:03:27.240038Z",
     "start_time": "2019-02-25T14:03:14.794482Z"
    }
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "v_file_set= []\n",
    "v_images_set = []\n",
    "\n",
    "images.extend(new)\n",
    "images.extend(origin)\n",
    "\n",
    "[v_file_set.append(images[i:i+242]) for i in range(0, len(images), 242)]\n",
    "v_images_set = np.asarray(v_file_set)\n",
    "# images = np.asarray(img_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T14:03:27.255368Z",
     "start_time": "2019-02-25T14:03:27.241860Z"
    }
   },
   "outputs": [],
   "source": [
    "v_images_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T14:03:27.259450Z",
     "start_time": "2019-02-25T14:03:27.257047Z"
    }
   },
   "outputs": [],
   "source": [
    "v_data=v_images_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# music data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T04:06:27.471955Z",
     "start_time": "2019-02-26T04:06:27.465951Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "%cd '' # 음악 cutting 파일들이 있는 경로로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T04:06:27.963173Z",
     "start_time": "2019-02-26T04:06:27.954613Z"
    }
   },
   "outputs": [],
   "source": [
    "m_file_list = os.listdir()\n",
    "m_file_list.sort()\n",
    "len(m_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T04:06:29.622800Z",
     "start_time": "2019-02-26T04:06:29.618905Z"
    }
   },
   "outputs": [],
   "source": [
    "m_file_list2=[]\n",
    "m_file_set = []\n",
    "for i in m_file_list:\n",
    "    if 'wav' in i:\n",
    "        m_file_list2.append(i)\n",
    "\n",
    "# [m_file_set.append(m_file_list2[i:i+242]) for i in range(0, len(m_file_list2), 242)]\n",
    "# len(m_file_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-26T04:06:33.334Z"
    }
   },
   "outputs": [],
   "source": [
    "m_data=[]\n",
    "\n",
    "for idx,i in enumerate(m_file_list2):\n",
    "    if idx < 2000:\n",
    "        y, sr = librosa.load('{}'.format(i))\n",
    "        label=librosa.feature.melspectrogram(y=y, sr=sr,hop_length=512)\n",
    "#       norm_label=librosa.util.normalize(label, norm=1)\n",
    "        label=minmax_scale(label)\n",
    "        m_data.append(label)\n",
    "\n",
    "m_data = np.asarray(m_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-26T04:06:34.043Z"
    }
   },
   "outputs": [],
   "source": [
    "m_data = m_data.reshape((m_data.shape[0],m_data.shape[2],m_data.shape[1]))\n",
    "m_data.shape # (sample,timeseries,feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-26T04:06:42.867Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.random.randint(low=1,high=2,size=550)\n",
    "b = np.random.randint(low=0,high=1,size=1450)\n",
    "\n",
    "label = []\n",
    "label.extend(a)\n",
    "label.extend(b)\n",
    "label = np.float32(np.expand_dims(label, 1))\n",
    "np.asarray(label).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T02:56:24.148298Z",
     "start_time": "2019-02-26T02:53:58.902113Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "v_input_shape = (242, 150, 150, 3)\n",
    "m_input_shape = (1292,128)\n",
    "v_input = Input(v_input_shape)\n",
    "m_input = Input(m_input_shape)\n",
    "\n",
    "base_model = InceptionV3(weights=None, include_top=False, pooling='max')\n",
    "inception_layer = TimeDistributed(base_model)(v_input)\n",
    "Drop_layers = keras.layers.Dropout(0.3)(inception_layer)\n",
    "inception_layer2 = TimeDistributed(Dense(128))(Drop_layers)\n",
    "LSTM_layer = LSTM(242)(inception_layer2)\n",
    "Drop_layers2 = keras.layers.Dropout(0.3)(LSTM_layer)\n",
    "output = Dense(128)(Drop_layers2)\n",
    "v_model = Model(v_input,output)\n",
    "\n",
    "m_model = Sequential()\n",
    "m_model.add(LSTM(242, input_shape = m_input_shape, return_sequences=True))\n",
    "m_model.add(Dropout(0.3))\n",
    "m_model.add(Flatten())\n",
    "m_model.add(Dense(128))\n",
    "\n",
    "encoded_v = output\n",
    "encoded_m = m_model(m_input)\n",
    "\n",
    "def euclidean_distance(vecter1):\n",
    "    x, y = vecter1\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis = 1, keepdims=True))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 3\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance, output_shape = eucl_dist_output_shape)([encoded_v,encoded_m])\n",
    "# cosine = keras.layers.dot([encoded_v,encoded_m],axes=-1, normalize=True)\n",
    "# both = Lambda(L1_distance,output_shape = lambda x: x[0])([encoded_v,encoded_m])\n",
    "# both = merge([encoded_v,encoded_m], mode=L1_distance , output_shape = lambda x: x[0])\n",
    "# https://github.com/eriklindernoren/Keras-GAN/issues/83 Lambda 참조\n",
    "siamese_net = Model(inputs=[v_input,m_input],outputs=distance) \n",
    "\n",
    "\n",
    "siamese_net = multi_gpu_model(siamese_net, gpus=8)\n",
    "siamese_net.compile(loss = contrastive_loss,\n",
    "              optimizer = optimizers.RMSprop(lr=0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T19:26:30.994127Z",
     "start_time": "2019-02-25T15:52:29.659510Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='acc', patience=)\n",
    "hist = siamese_net.fit([v_data,m_data],\n",
    "                     label , \n",
    "                     epochs = 30, \n",
    "                     verbose = 1, \n",
    "                     batch_size = 8, \n",
    "                     shuffle = True, \n",
    "                     validation_split = 0.2)\n",
    "#                      callbacks = [early_stopping])\n",
    "print('## training loss and acc ##')\n",
    "print(hist.history['loss'], '\\n')\n",
    "print(hist.history['acc'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-24T15:35:00.609Z"
    }
   },
   "outputs": [],
   "source": [
    "# siamese_net.predict([test_set,m_data])\n",
    "m_model.predict(m_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 전체 저장 - 경로 지정\n",
    "siamese_net.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T05:10:33.666415Z",
     "start_time": "2019-02-25T05:10:28.094139Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델의 weight를 저장하기 - 경로 지정\n",
    "siamese_net.save_weights('final_model_weight.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_model만 저장 - 경로 지정\n",
    "v_model.save('v_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_model의 weight를 저장하기 - 경로 지정\n",
    "v_model.save_weights('v_model_weight.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_model만 저장 - 경로 지정\n",
    "m_model.save('m_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_model의 weight를 저장하기 - 경로 지정\n",
    "m_model.save_weights('m_model_weight.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T03:03:09.277325Z",
     "start_time": "2019-02-26T03:03:09.266151Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 확인\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:47:31.118250Z",
     "start_time": "2019-02-23T17:30:33.261Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델을 json파일로 저장하기\n",
    "model_json = siamese_net.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "\n",
    "# 모델의 weight를 저장하기\n",
    "seiamese_net.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:47:31.119059Z",
     "start_time": "2019-02-23T17:30:33.268Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 저장된 모델 불러오기\n",
    "# from keras.models import model_from_json\n",
    "# json_file = open(\"model.json\", \"r\") \n",
    "# loaded_model_json = json_file.read() \n",
    "# json_file.close() \n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# # 불러온 모델에 weight 적용하기\n",
    "# loaded_model.load_weights(\"model.h5\") \n",
    "# print(\"Loaded model from disk\")\n",
    "\n",
    "# # 모델에 weight 적용시켜 모델 돌리기\n",
    "\n",
    "# loaded_model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "\n",
    "# # model evaluation\n",
    "# score = loaded_model.evaluate(X,Y,verbose=0)\n",
    "\n",
    "# print(\"%s : %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
